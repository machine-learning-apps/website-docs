{
  
  "0": {
    "title": "",
    "content": "404 . Page not found :( . The requested page could not be found. .",
    "url": "http://0.0.0.0:4000/404.html",
    "relUrl": "/404.html"
  }
  ,"1": {
    "title": "About",
    "content": "About . These docs are maintained by the this team. . Contributing . The source for these docs are hosted here. We welcome contributions. .",
    "url": "http://0.0.0.0:4000/about/",
    "relUrl": "/about/"
  }
  ,"2": {
    "title": "Argo",
    "content": "Deploy Machine Learning Workflows With Argo . What are Argo Workflows? . From the docs: . Argo Workflows is an open source container-native workflow engine for orchestrating parallel jobs on Kubernetes. Argo Workflows is implemented as a Kubernetes CRD (Custom Resource Definition). . | Define workflows where each step in the workflow is a container. Model multi-step workflows as a sequence of tasks or capture the dependencies between tasks using a graph (DAG). | Easily run compute intensive jobs for machine learning or data processing in a fraction of the time using Argo Workflows on Kubernetes. | Run CI/CD pipelines natively on Kubernetes without configuring complex software development products. | . The Argo GitHub Action . See this repo for full context. . A Hello-World Workflow . name: ML Workflows Via Actions on: [push] jobs: build: runs-on: ubuntu-latest steps: # This copies the files in this repo, particulary the yaml workflow spec needed for Argo. - name: Step One - checkout files in repo uses: actions/checkout@master # Get credentials (the kubeconfig file) the k8 cluster. Copies kubeconfig into /github/workspace/.kube/config - name: Step Two - Get kubeconfig file from GKE uses: machine-learning-apps/gke-kubeconfig@master with: application_credentials: $ project_id: $ location_zone: $ cluster_name: $ ################################################### # This is the action that submits the Argo Workflow - name: Step Three - Submit Argo Workflow from the examples/ folder in this repo id: argo uses: machine-learning-apps/actions-argo@master with: argo_url: $ # below is a reference to a YAML file in this repo that defines the workflow. workflow_yaml_path: &quot;examples/coinflip.yaml&quot; parameter_file_path: &quot;examples/arguments-parameters.yaml&quot; env: # KUBECONFIG tells kubectl where it can find your authentication information. A config file was saved to this path in Step Two. KUBECONFIG: &#39;/github/workspace/.kube/config&#39; # This step displays the Argo URL, and illustrates how you can use the output of the previous Action. - name: test argo outputs run: echo &quot;Argo URL $WORKFLOW_URL&quot; env: WORKFLOW_URL: $ . Running Argo On Self Hosted Runners . You can skip the .kubeconfig if your Actions runner is running on a self-hosted runner on your Kubernetes cluster that has access to Argo. See these docs for further instructions. .",
    "url": "http://0.0.0.0:4000/docs/kubernetes/argo.html",
    "relUrl": "/docs/kubernetes/argo.html"
  }
  ,"3": {
    "title": "Experiment Tracking",
    "content": "Experiment tracking for machine learning involves logging of metrics and artificacts associated with different training runs. This is essential for effective mlops as it allows you to track your performance metrics and promotes reproduceability in a transparent, reuseable way. . There are several experiment tracking systems available as third-party solutions that GitHub Actions can integrate with. For example, the below example illustrates how results of a training run can be fetched from Weights and Biases and dropped into a pull request: . &lt;/img&gt; .",
    "url": "http://0.0.0.0:4000/docs/experiment_tracking/experiment_tracking.html",
    "relUrl": "/docs/experiment_tracking/experiment_tracking.html"
  }
  ,"4": {
    "title": "Blog with fastpages",
    "content": "fastai/fastpages: Blogging with Jupyter Notebooks . . From the project page: . fastpages uses GitHub Actions to simplify the process of creating Jekyll blog posts on GitHub Pages from a variety of input formats. . fastpages provides the following features: . Create posts containing code, outputs of code (which can be interactive), formatted text, etc directly from Jupyter Notebooks; Notebook posts support features such as: Interactive visualizations made with Altair remain interactive. | Hide or show cell input and output. | Collapsable code cells that are either open or closed by default. | Define the Title, Summary and other metadata via a special markdown cells | Ability to add links to Colab and GitHub automatically. | . | Support for comments, supported natively through GitHub Issues. | Built-in search. | Support for customizing the styling of your site. | Embed Twitter cards and YouTube videos. | Categorization of blog posts by user-supplied tags for discoverability. | Create and edit Markdown posts. | Create posts, including formatting and images, directly from Microsoft Word documents. | Write posts on your local machine and preview them with live reload. | . See the project for more details. .",
    "url": "http://0.0.0.0:4000/docs/fastpages",
    "relUrl": "/docs/fastpages"
  }
  ,"5": {
    "title": "",
    "content": "What is MLOps? . From Wikipedia: . MLOps (a compound of “machine learning” and “operations”) is a practice for collaboration and communication between data scientists and operations professionals to help manage production ML (or deep learning) lifecycle.[1] Similar to the DevOps or DataOps approaches, MLOps looks to increase automation and improve the quality of production ML while also focusing on business and regulatory requirements. While MLOps also started as a set of best practices, it is slowly evolving into an independent approach to ML lifecycle management. MLOps applies to the entire lifecycle - from integrating with model generation (software development lifecycle, continuous integration/continuous delivery), orchestration, and deployment, to health, diagnostics, governance, and business metrics. . How Can GitHub Help With MLOps? . There are a series of new and emerging features that can aid with MLOps. Some feautres that are relevant incldue Actions and CodeSpaces. . Contributing . Contribution to this site and docs are welcome. You can make pull requests or open issues on this GitHub repo. If you are unsure on whether or not your content is appropriate for this site, please open an issue. .",
    "url": "http://0.0.0.0:4000/",
    "relUrl": "/"
  }
  ,"6": {
    "title": "Jupyter",
    "content": "There are many interesting things you can do with Actions, and CodeSpaces to compliment jupyter notebooks on GitHub. .",
    "url": "http://0.0.0.0:4000/docs/jupyter/jupyter.html",
    "relUrl": "/docs/jupyter/jupyter.html"
  }
  ,"7": {
    "title": "Kubernetes",
    "content": "Resources for MLOps on Kubernetes with GitHub. This is useful if you need to access broader infrastructure resources in your machine learning workflows. For example: . Deploying and serving models, including a service mesh | Deploying and serving arbitrary applications, such as Jupyter Notebooks or documentation sites. | Accessing other resources that are visible from your internal k8s cluster, such as: Databases, i.e. Presto, Hive | Storage, i.e. HDFS | Distributed data processing, such as Dask or Spark | Specialized computing such as GPUs. | Integration with experiment tracking systems. | . | Access to secrets. | Native resource management and kubernetes for scalability and resiliance. | Interoperability with machine learning or data pipelines, such as Argo, MLFlow, Prefect, etc. | … and much more. | .",
    "url": "http://0.0.0.0:4000/docs/kubernetes/kubernetes.html",
    "relUrl": "/docs/kubernetes/kubernetes.html"
  }
  ,"8": {
    "title": "Programatically run notebooks",
    "content": "Refresh Jupyter Notebooks With Papermill . papermill is a great project for running notebooks programatically. You can pass parameters to notebooks, use different kernels, etc. . Example: refresh notebooks every 6 hours . Put a shell script at the location_action_files/run_notebooks.sh with the following contents: . #!/bin/sh set -e cd $(dirname &quot;$0&quot;)/.. cd _notebooks/ ERRORS=&quot;&quot; # Loop through all notebooks and run them with papermill for file in *.ipynb do if papermill --kernel python3 &quot;${file}&quot; &quot;${file}&quot;; then echo &quot;Sucessfully refreshed ${file} n n n n&quot; else echo &quot;ERROR Refreshing ${file}&quot; ERRORS=&quot;${ERRORS}, ${file}&quot; fi done # Emit Errors If Exists So Downstream Task Can Open An Issue if [ -z &quot;$ERRORS&quot; ] then echo &quot;::set-output name=error_bool::false&quot; else echo &quot;These files failed to update properly: ${ERRORS}&quot; echo &quot;::set-output name=error_bool::true&quot; echo &quot;::set-output name=error_str::${ERRORS}&quot; fi . In the location .github/workflows/update-nb.yaml define an Actions workflow with the following contents . name: Update Notebooks And Refresh Page on: schedule: - cron: &#39;0 */6 * * *&#39; jobs: update-notebooks: runs-on: ubuntu-latest steps: - name: Copy Repository Contents uses: actions/checkout@v2 - name: Set up Python uses: actions/setup-python@v1 with: python-version: 3.6 - name: install dependencies run: | pip3 install -r ./_notebooks/requirements.txt python3 -m ipykernel install --user --name python3 sudo chmod -R 777 . - name: update notebooks id: update_nb run: | ./_action_files/run_notebooks.sh - name: Create an issue if notebook update failure occurs if: steps.update_nb.outputs.error_bool == &#39;true&#39; uses: actions/github-script@0.6.0 with: github-token: $ script: | var err = process.env.ERROR_STRING; var run_id = process.env.RUN_ID; github.issues.create({ owner: context.repo.owner, repo: context.repo.repo, title: &quot;Error updating notebooks&quot;, body: `These are the notebooks that failed to update properly: n${err} n n See run [${run_id}](https://github.com/github/covid19-dashboard/actions/runs/${run_id}) for more details.` }) env: ERROR_STRING: $ RUN_ID: $ . This example is based on covid19dashboards.com, which uses fastpages and papermill to refresh notebooks and serve them as dasbhoards. You can see browse the workflow files of this project to see how papermill is used. .",
    "url": "http://0.0.0.0:4000/docs/jupyter/papermill.html",
    "relUrl": "/docs/jupyter/papermill.html"
  }
  ,"9": {
    "title": "Containerize repos as a Jupyter server",
    "content": "The repo2docker Action . repo2docker is a project that will automatically create a docker image of your GitHub repository based on configuration files found in the repository, with additional Jupyter or RStudio support (depending upon the configuration files found). . This is extremely useful for serving Jupyter notebooks automatically from GitHub repos. . The repo2docker action packages this functionality in an easy-to-use interface that can be triggered in your GitHub workflows. For example, you can build a Jupyter-enabled Docker image of your repository like so: . name: Build Notebook Container on: [push] # You may want to trigger this Action on other things than a push. jobs: build: runs-on: ubuntu-latest steps: - name: checkout files in repo uses: actions/checkout@master - name: update jupyter dependencies with repo2docker uses: machine-learning-apps/repo2docker-action@master with: DOCKER_USERNAME: $ DOCKER_PASSWORD: $ . Additionally, this action allows you to pre-cache images for your own BinderHub cluster, or for mybinder.org. .",
    "url": "http://0.0.0.0:4000/docs/jupyter/repo2docker.html",
    "relUrl": "/docs/jupyter/repo2docker.html"
  }
  ,"10": {
    "title": "Self-Hosted K8s Actions Runner",
    "content": "Create A Self-Hosted Actions Runner On Your Kubernetes Cluster With 3 Commands . Motivation . GitHub Actions allow you to use self hosted runners. From the docs: . Self-hosted runners offer more control of hardware, operating system, and software tools than GitHub-hosted runners provide. With self-hosted runners, you can choose to create a custom hardware configuration with more processing power or memory to run larger jobs, install software available on your local network, and choose an operating system not offered by GitHub-hosted runners. Self-hosted runners can be physical, virtual, in a container, on-premises, or in a cloud. . This repository shows how to run a self hosted runner in a Kubernetes cluster, which is useful if your Actions runner needs to create resources or update deployments. .",
    "url": "http://0.0.0.0:4000/docs/kubernetes/self-hosted-runners.html",
    "relUrl": "/docs/kubernetes/self-hosted-runners.html"
  }
  ,"11": {
    "title": "Weights & Biases",
    "content": "Fetch Runs From Weights &amp; Biases . Weights and Biases is a system for experiment tracking, model optimization, and dataset versioning. . The Weights and Biases (W&amp;B) Action can help you fetch runs from W&amp;B for reporting in your GitHub workflows. . This Action saves a csv file called wandb_report.csv into the path specified by the default environment variable GITHUB_WORKSPACE set for you in GitHub Actions, which allows this data to be accessed by subsequent Actions. Information in this CSV can be displayed in a variety of ways, such as a markdown formatted comment in a pull request or via the GitHub Checks API. . This csv file always has the following fields: . run.url: the url for the run in the W&amp;B api. | run.name: the name of the run. This is automatically set by wandb if not specified by the user. | run.tags: a list with all of the tags assigned to the run. | run.id: the id associated with the run. This corresponds to the input RUN_ID | run.entity: this name of the entity that contains the project the run can be found in. This is similar to an org in GitHub. | run.project: the name of the project that contains the run. This is simlar to a repo in GitHub. | github_sha: the config variable github_sha. | __eval.category: this field will contain either the value candiate or baseline, depending on how the run was queried. | . In addition to the above fields the user can specify additional fields. . Below is an example of how this Action can be used to fetch model runs: . name: Get WandB Runs on: [issue_comment] jobs: get-runs: if: (github.event.issue.pull_request != null) &amp;&amp; contains(github.event.comment.body, &#39;/get-runs&#39;) runs-on: ubuntu-latest steps: - name: Get the latest SHA for the PR that was commented on id: chatops uses: machine-learning-apps/actions-chatops@master with: TRIGGER_PHRASE: &quot;/get-runs&quot; env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} - name: Get Runs Using SHA uses: machine-learning-apps/wandb-action@master with: PROJECT_NAME: ${{ format(&#39;{0}/{1}&#39;, secrets.WANDB_ENTITY, secrets.WANDB_PROJECT) }} FILTER_GITHUB_SHA: ${{ steps.chatops.outputs.SHA }} BASELINE_TAGS: &quot;[&#39;baseline&#39;, &#39;reference&#39;]&quot; DISPLAY_METRICS: &quot;[&#39;accuracy&#39;, &#39;loss&#39;, &#39;best_val_acc&#39;, &#39;best_val_loss&#39;, &#39;_runtime&#39;]&quot; WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }} DEBUG: &#39;true&#39; . See this project for more information. .",
    "url": "http://0.0.0.0:4000/docs/experiment_tracking/wandb.html",
    "relUrl": "/docs/experiment_tracking/wandb.html"
  }
  
}